{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import cv2\n",
    "import itertools\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "from os import listdir\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to load the images given the folder name\n",
    "def load_folder(folder, num_samples):\n",
    "    imgs = []\n",
    "    files = listdir('./MIO-TCD-Classification/train/{}/'.format(folder))\n",
    "    img_counter = 0\n",
    "    for img in files:\n",
    "        # Read the images in grayscale\n",
    "        img = cv2.cvtColor(cv2.imread('./MIO-TCD-Classification/train/{}/{}'.format(folder,img)), cv2.COLOR_BGR2GRAY)\n",
    "        # Perform a box blur on the images\n",
    "        kernel = np.array([[1/9,1/9,1/9], [1/9,1/9,1/9], [1/9,1/9,1/9]])\n",
    "        img = cv2.filter2D(img, -1, kernel)\n",
    "        # Resize to reduce computation time\n",
    "        img = cv2.resize(img, (64,64))\n",
    "        imgs.append(img)\n",
    "        img_counter += 1\n",
    "        if(img_counter==num_samples): break\n",
    "    print('Number of samples from ' + folder + '=' + str(len(imgs)))\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples from articulated_truck=10000\n",
      "Number of samples from bicycle=2284\n",
      "Number of samples from bus=10000\n",
      "Number of samples from car=10000\n",
      "Number of samples from motorcycle=1982\n",
      "Number of samples from non-motorized_vehicle=1751\n",
      "Number of samples from pedestrian=6262\n",
      "Number of samples from pickup_truck=10000\n",
      "Number of samples from single_unit_truck=5120\n",
      "Number of samples from work_van=9679\n"
     ]
    }
   ],
   "source": [
    "# The number of images from each class to import\n",
    "num_samples = 10000\n",
    "# Import images from each folder\n",
    "articulated_truck = load_folder('articulated_truck', num_samples)\n",
    "bicycle = load_folder('bicycle', num_samples)\n",
    "bus = load_folder('bus', num_samples)\n",
    "car = load_folder('car', num_samples)\n",
    "motorcycle = load_folder('motorcycle', num_samples)\n",
    "non_motorized_vehicle = load_folder('non-motorized_vehicle', num_samples)\n",
    "pedestrian = load_folder('pedestrian', num_samples)\n",
    "pickup_truck = load_folder('pickup_truck', num_samples)\n",
    "single_unit_truck = load_folder('single_unit_truck', num_samples)\n",
    "work_van = load_folder('work_van', num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67078\n",
      "Number of samples from background=67078\n"
     ]
    }
   ],
   "source": [
    "objects = articulated_truck + bicycle + bus + car + motorcycle + non_motorized_vehicle + pedestrian + pickup_truck + single_unit_truck + work_van\n",
    "bg_samples  = len(objects)\n",
    "print(bg_samples)\n",
    "background = load_folder('background', bg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to compute HoG features of a list of images\n",
    "# Adapted from Tutorial 4, Part 2\n",
    "def compute_HoG(imgs, cell_size, block_size, nbins, h, w):\n",
    "    img_features = []\n",
    "    hog = cv2.HOGDescriptor(_winSize=((w // cell_size[1]) * cell_size[1],\n",
    "                                  (h // cell_size[0]) * cell_size[0]),\n",
    "                        _blockSize=(block_size[1] * cell_size[1],\n",
    "                                    block_size[0] * cell_size[0]),\n",
    "                        _blockStride=(cell_size[1], cell_size[0]),\n",
    "                        _cellSize=(cell_size[1], cell_size[0]),\n",
    "                        _nbins=nbins)\n",
    "    n_cells = (h // cell_size[0], w // cell_size[1])\n",
    "    \n",
    "    for img in imgs:\n",
    "\n",
    "        hog_feats = hog.compute(img)\\\n",
    "                .reshape(n_cells[1] - block_size[1] + 1,\n",
    "                        n_cells[0] - block_size[0] + 1,\n",
    "                        block_size[0], block_size[1], nbins) \\\n",
    "               .transpose((1, 0, 2, 3, 4))  # index blocks by rows first\n",
    "                \n",
    "        # computation for BlockNorm\n",
    "\n",
    "        gradients = np.full((n_cells[0], n_cells[1], nbins), 0, dtype=float)\n",
    "        cell_count = np.full((n_cells[0], n_cells[1], 1), 0, dtype=int)\n",
    "\n",
    "        for off_y in range(block_size[0]):\n",
    "            for off_x in range(block_size[1]):\n",
    "                gradients[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                          off_x:n_cells[1] - block_size[1] + off_x + 1] += \\\n",
    "                    hog_feats[:, :, off_y, off_x, :]\n",
    "                cell_count[off_y:n_cells[0] - block_size[0] + off_y + 1,\n",
    "                           off_x:n_cells[1] - block_size[1] + off_x + 1] += 1\n",
    "\n",
    "        # Average gradients\n",
    "        gradients /= cell_count\n",
    "        \n",
    "        img_features.append(gradients)\n",
    "        \n",
    "    return img_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = objects + background\n",
    "y = ['object']*len(objects) + ['background']*len(background)\n",
    "\n",
    "# Split the data into a training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=69)\n",
    "\n",
    "# Define parameters for computing the HoG features\n",
    "c_size = (4,4)\n",
    "b_size = (4,4)\n",
    "bins = 8\n",
    "height = 64\n",
    "width = 64\n",
    "\n",
    "# Compute the HoG Features\n",
    "HoG_feat = compute_HoG(X_train, c_size, b_size, bins, height, width)\n",
    "HoG_feat = np.array(HoG_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components used: 518\n"
     ]
    }
   ],
   "source": [
    "# Compute PCA for all components\n",
    "pca = PCA(n_components = 2048)\n",
    "X_PCA = pca.fit_transform(HoG_feat.reshape(HoG_feat.shape[0],-1))\n",
    "# Find the variances explained\n",
    "marginal_variances = pca.explained_variance_ratio_\n",
    "\n",
    "total_variances = [sum(marginal_variances[:i]) for i in range(1,len(marginal_variances)+1)]\n",
    "\n",
    "# Use the number of components representing 98% of the data\n",
    "nb_components = next(x[0] for x in enumerate(total_variances) if x[1] > 0.98)\n",
    "print('Number of components used: ' + str(nb_components))\n",
    "pca = PCA(n_components = nb_components)\n",
    "# Prepare training data\n",
    "X_train_PCA = pca.fit_transform(HoG_feat.reshape(HoG_feat.shape[0],-1))\n",
    "# Prepare test data\n",
    "HoG_feat_test = compute_HoG(X_test, c_size, b_size, bins, height, width)\n",
    "HoG_feat_test = np.array(HoG_feat_test)\n",
    "X_test_PCA = pca.transform(HoG_feat_test.reshape(HoG_feat_test.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LinearSVC = 18.826839335036233\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "then = time.clock()\n",
    "svc_clf = LinearSVC()\n",
    "svc_clf.fit(X_train_PCA,y_train)\n",
    "now = time.clock()\n",
    "elapsed = now - then\n",
    "print('Time to train LinearSVC = ' + str(elapsed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to predict using LinearSVC = 0.03180265962888029\n",
      "LinearSVC Prediction Results\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " background       0.91      0.91      0.91     10073\n",
      "     object       0.91      0.91      0.91     10051\n",
      "\n",
      "avg / total       0.91      0.91      0.91     20124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict the classes\n",
    "then = time.clock()\n",
    "svc_pred = svc_clf.predict(X_test_PCA)\n",
    "now = time.clock()\n",
    "elapsed = now - then\n",
    "print('Time to predict using LinearSVC = ' + str(elapsed))\n",
    "print('LinearSVC Prediction Results')\n",
    "print(classification_report(y_test,svc_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.294910474377048\n"
     ]
    }
   ],
   "source": [
    "then = time.clock()\n",
    "lr_clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial')\n",
    "lr_clf.fit(X_train_PCA,y_train)\n",
    "now = time.clock()\n",
    "print(now - then)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.060136461610909464\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      " background       0.91      0.91      0.91     10073\n",
      "     object       0.91      0.91      0.91     10051\n",
      "\n",
      "avg / total       0.91      0.91      0.91     20124\n",
      "\n"
     ]
    }
   ],
   "source": [
    "then = time.clock()\n",
    "lr_pred = lr_clf.predict(X_test_PCA)\n",
    "now = time.clock()\n",
    "print(now - then)\n",
    "print(classification_report(y_test,lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Localization Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to load the images given the folder name\n",
    "def load_folder(num_samples):\n",
    "    imgs = []\n",
    "    files = listdir('./MIO-TCD-Localization/train/')\n",
    "    img_counter = 0\n",
    "    for img in files:\n",
    "        # Read the images in grayscale\n",
    "        img = cv2.cvtColor(cv2.imread('./MIO-TCD-Localization/train/{img}'.format(img=img)), cv2.COLOR_BGR2GRAY)\n",
    "        # Perform a box blur on the images\n",
    "        kernel = np.array([[1/9,1/9,1/9], [1/9,1/9,1/9], [1/9,1/9,1/9]])\n",
    "        img = cv2.filter2D(img, -1, kernel)\n",
    "        # Resize to reduce computation time\n",
    "        imgs.append(img)\n",
    "        img_counter += 1\n",
    "        if(img_counter==num_samples): break\n",
    "    return imgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of images from each class to import\n",
    "num_samples = 100\n",
    "# Import images from each folder\n",
    "background_img = load_folder(num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize factor for the image\n",
    "resize_factor = 1/1.6\n",
    "\n",
    "data_size = (64,64)\n",
    "\n",
    "# get the dimensions of it to iterate through it\n",
    "window_size = (72, 48)\n",
    "\n",
    "windows = []\n",
    "\n",
    "# iterate through list of images \n",
    "for i in range(len(background_img)):\n",
    "    # get group photo in gray\n",
    "    img_gray = background_img[i]\n",
    "    \n",
    "    windows.append([])\n",
    "    grp_x, grp_y = img_gray.shape\n",
    "    \n",
    "    # iterate through the image and then resize the image each time\n",
    "    #while(grp_x>window_size[0] and grp_y>window_size[1]):\n",
    "    \n",
    "    for y in range(0, grp_y-window_size[1], 20):\n",
    "        for x in range(0, grp_x-window_size[0], 20):\n",
    "            section = img_gray[x:x+window_size[0], y:y+window_size[1]]\n",
    "            patch = cv2.resize(section, data_size)\n",
    "\n",
    "            img = []\n",
    "            img.append(patch)\n",
    "            HoG = compute_HoG(img, c_size, b_size, bins, height, width)\n",
    "            HoG = np.asarray(HoG)\n",
    "            test_img = pca.transform(HoG.reshape(HoG.shape[0],-1))\n",
    "            pred = lr_clf.predict(test_img)\n",
    "            if(pred == 'object'):\n",
    "                plt.imshow(patch)\n",
    "                plt.show\n",
    "                windows[i].append(patch)\n",
    "                    \n",
    "        #img_gray = cv2.resize(img_gray, (0,0), fx=resize_factor, fy=resize_factor) \n",
    "        #grp_x, grp_y = img_gray.shape\n",
    "\n",
    "print(len(windows))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
